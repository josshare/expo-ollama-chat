# ðŸŽ¯ Quick Start Guide

## Single Command Setup:
```bash
npm start
```

## What happens when you run `npm start`:

1. **âœ… Checks Ollama Installation**
   - Verifies Ollama is installed
   - Shows installation instructions if missing

2. **ðŸ“¦ Installs Dependencies** 
   - Creates Expo app with TypeScript
   - Installs all required packages

3. **ðŸ¤– Downloads AI Model**
   - Pulls `llama3.2:1b` (1.3GB, fast model)
   - Tests model connection
   - Shows progress and status

4. **ðŸš€ Starts Development Server**
   - Launches Expo with cleared cache
   - Ready for iOS/Android/Web testing

## Manual Steps (if needed):

```bash
# 1. Install Ollama first
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Then run the project
npm start
```

## After Setup:

- ðŸ“± Scan QR code with Expo Go app
- ðŸ’¬ Start chatting with your offline AI
- ðŸ”’ 100% private - no internet needed!

## File Structure:
```
expo-ollama-chat/
â”œâ”€â”€ App.tsx              # Main chat interface
â”œâ”€â”€ services/
â”‚   â””â”€â”€ OllamaService.ts # API client
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ check-ollama.js  # Installation checker  
â”‚   â””â”€â”€ setup-model.js   # Model downloader
â””â”€â”€ package.json         # One-line setup
```

**ðŸŽ‰ That's it! Your offline AI chat app is ready!**